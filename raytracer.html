<!DOCTYPE html>
<html>

<head>
    <link rel="stylesheet" type="text/css" href="/static/style.css">
    <title>Raytracer</title>

</head>

<body>

    <!--navbar-->
    <ul>
        <li><a href="/">About Me</a></li>
        <li><a href="./aboutsite">About This Site</a></li>
        <li class="dropdown">
            <a class="dropbtn">Project Articles</a>
            <div class="dropdown-content">
                <a href="#">Raytracer</a>
                <a href="./bayes">Naive Bayes Classifier</a>
            </div>
        </li>
        <li class="dropdown">
            <a class="dropbtn">Interactive Projects</a>
            <div class="dropdown-content">
                <a href="./linear">Linear Regression Model</a>
                <a href="./connect4">Connect 4 Bot - Video Demo</a>
            </div>
        </li>
    </ul>
    <!--navbar-->

    <figure>
    <h1>Building A Multithreaded Raytracer From Scratch</h1>
    <figcaption><a target="_blank" href="https://github.com/HiddenToad/raytracer-rs" style="font-size: 1.2em !important;">Github Repo Link</a></figcaption>
    </figure>
    <br><br>
    <div class="articletext">
        <h2>What is raytracing?</h2>
        <p>Raytracing is a type of 3D rendering where the shapes are rendered by tracing the paths of simulated "rays" of light through the scene. This allows for more realistic, naturally lit images with shadows, reflections, and textures all looking
            more realistically illuminated. Many modern video games have support for real-time raytracing, and nearly every 3D animated movie in the past couple decades has used it. Pixar Animation Studios first used a raytracing renderer in the 2006
            movie <cite>Cars</cite>.
        </p>
        <br/>
        <figure>
            <img src="static/raytracer/kachow.jpg" class="articleimage"/>
            <figcaption>Raytraced lighting in <cite>Cars (2006)</cite> gives the body of the protagonist a polished, glossy feel.</figcaption>
        </figure>
        
        <br/>
        <h2>Features</h2>
        <p>
            I created this raytracer entirely from scratch, meaning I didn't use any libraries to create it, only my own code. This was quite a challenging project to get right, and probably the project I'm most proud of to date. 
            The math involved is pretty complex,
            and it took many tries to get everything to look natural and realistic. 
        </p>
        <p>
            The raytracer I created is pretty limited in function. To start off, it can only render spheres. The formula for a ray's collision with a sphere was complicated enough for me to implement as it is; to implement it to work with an arbitrary
            3D model would be beyond the scope of my time or abilities. There are 2 materials a rendered sphere can have: Lambertian (a matte solid) and metallic (shiny metal that reflects and blurs). I tried implementing dielectrics (something that
            is transparent but refracts, like glass or water) but couldn't get it to look right. For any sphere, you can choose its position, radius, color, and material, as well as blur for metal spheres. The camera is pretty full-feature: you can 
            set field of view, position, position to look at, lens aperture (which mainly affects the depth-of-field blur affect), and the distance from the lens to focus on. 
        </p>
        <p>
            The other feature that I implemented for the renderer is concurrency. Concurrency, also known as multithreading, means that instead of your computer following each step of a task
            in a row, it will split up the task into multiple parts that can be handled simultaneously by different threads of the CPU. Think of it like hiring multiple workers to do different parts of a complex job, versus having one guy do it all alone.
            This can be a game-changer for intense tasks that have a lot of repetitive steps, like rendering.
            Essentially, I divvy up the final image into chunks, and create workers called "threads" that are responsible for rendering each section simultaneously. When each thread finishes, it sends the final image to the main thread, 
            along with its ID number. Once all the workers are done, the main thread assembles the segments in order using the ID numbers. Making my raytracer concurrent in this way dropped my render times by nearly 25%. 
        </p>

        <br><br>
        <h1>Basic rendering</h2>
        <figure>
            <img src="static/raytracer/lone-sphere-256s.png" class="articleimage">
            <figcaption>A single red sphere rendered on an empty plane.</figcaption>
        </figure>
        <p>
            I'm not going to go into the specific math behind the rendering; it would be outside the scope of this article. The basic method for rendering is to simulate rays of light traveling through the scene, using their points of collision
            to realistically render the scene. This light-centric rendering makes natural shading and shadows better than many other rendering methods. This is a simple sphere rendered on a plane (which is actually just a really large sphere)
            using the fully completed engine. I'm going to show you some other images that illustrate the different features used in the renderer, as well as a final demo image at the end.
        </p>
        <h1>Anti-aliasing</h2>
        <div class="sidebyside">
            <figure>
                <img src="static/raytracer/lone-sphere-0s.png" class="articleimage">
                <figcaption>1 sample per pixel</figcaption>
            </figure>
            <figure>
                <img src="static/raytracer/lone-sphere-16s.png" class="articleimage">
                <figcaption>16 samples per pixel</figcaption>
            </figure>
            <figure>
                <img src="static/raytracer/lone-sphere-64s.png" class="articleimage">
                <figcaption>64 samples per pixel</figcaption>
            </figure>
            <figure>
                <img src="static/raytracer/lone-sphere-128s.png" class="articleimage">
                <figcaption>128 samples per pixel</figcaption>
            </figure>
            <figure>
                <img src="static/raytracer/lone-sphere-256s.png" class="articleimage">
                <figcaption>256 samples per pixel</figcaption>
            </figure>
        </div>
        <p>Anti-aliasing is a technique used commonly in graphics to smooth images and remove visual noise. The method to achieve both these results is to send many rays at one pixel and average the color of all the samples. 
            Let's go deeper into why these issues happen, and why anti-aliasing can help solve them.
        </p>
        <h2>Noise</h2>
        <p>Noise can appear in rendered images, adding little dots all over it and ruining the image. The main reason this occurs is that the formulas used in raytracing are not 100% perfect. If a pixel is missed by all the rays sent, or if
            the precise angle of the ray results in a <a href="https://0.30000000000000004.com/" target="_blank">floating point error</a>, a pixel can be incorrectly rendered. Averaging the results of many rays sent at a pixel, rather than 
            trusting the results of a single ray, all but eliminates these anomalies. This creates a realistic looking image without noise.
        </p>
        <h2>Smoothing</h2>
        <p>Another problem with rendering with only 1 sample per pixel is that curves can look jagged and pixelated. If you simply render 100% color in a pixel if a ray collides there, and 0% color if it doesn't, your image will clearly
            show pixel boundaries. Anti-aliasing also fixes this. When you average out the colors over multiple samples, pixels that are near the edge of an object will smooth out, fading rather than abruptly stopping at the edge. This is
            particularly important for curved objects, where pixelated edges can really detract from the realism. Here's a close-up comparison of the edges of a sphere using 1 sample per pixel vs 256 samples.
        </p>
        <figure>
            <img src="static/raytracer/0s-smoothing.png" class="articleimage">
            <figcaption>1 sample per pixel. Besides the terrible noise, note the jagged edges.</figcaption>
        </figure>
        <figure>
            <img src="static/raytracer/256s-smoothing.png" class="articleimage">
            <figcaption>256 samples per pixel. Note the lack of noise, and smoothed out edges.</figcaption>
        </figure>
        <h2>Trade-offs</h2>
        <p>
            You may be wondering, "Why not use 1000 samples, just to be safe? Or 10000?". The issue with taking multiple samples per pixel is rendering times. Raytracing programs are highly intensive to run, and even on the small scale of this
            project can take minutes to render an image depending on the complexity of the scene, and the resolution of the image. Each additional sample per pixel adds another step that's being repeated thousands of times throughout rendering.
            The other reason is that there are significant diminishing returns for additional samples. You may have noticed in the side-by-side of different sampling amounts that 128 and 256 samples look very similar in quality. 
            The miniscule gain to visual fidelity is simply not worth the 2x or 4x increase to rendering times that using 512 or 1024 samples would inflict.
        </p>
        <br><br>
        <h1>Reflective Surfaces</h2>
        <p>For matte surfaces like the spheres I've been showing you, a simulated ray is reflected in a random way. If we remove the randomness, and use a formula for how the ray would bounce, we get relective surfaces! Before I go
            too far into explaining these, let me show you an example, using a single matte sphere and a single reflective one:
        </p>
        <figure>
            <img src="static/raytracer/reflective-2-nofuzz.png" class="articleimage">
            <figcaption>A matte sphere and a reflective sphere with no fuzz.</figcaption>
        </figure>
        <p>Here, we see demonstrated another amazing strength of raytracing renderers: it's incredibly simple to make realistic reflections. The rays that collide with the back of the matte sphere bounce off it, hitting the reflective one, and 
            traveling back to the camera lens! Because we're following rays of light, we get all kinds of realistic effects easily, such as the distortion that a mirrored sphere creates.
        </p>
        <h2>Fuzz</h1>
        <p>Perfect reflection works great for rendering a mirror-like object. If we want to make a shiny surface that reflects imperfectly, like metal, we need to introduce fuzz. The way we do this is pretty simple: we adjust the 
            trajectory of rays that are reflected off of the material by a small factor, kept within a certain range by a number between 0 and 1 that we supply when creating the material. No fuzz looks like a mirror, low fuzz looks like polished metal,
            high fuzz looks like dull metal, and max fuzz is basically useless because if you completely randomize the reflectance offset, it's just matte again. You know the deal, time for some pictures:
        </p>
        <div class="sidebyside" style="margin-left: -5vw !important" id="fuzz">
        <figure>
            <img src="static/raytracer/reflective-2-nofuzz.png" class="articleimage">
            <figcaption>The image you saw before. No fuzz looks like a mirror.</figcaption>
        </figure>
        <figure>
            <img src="static/raytracer/reflective-2.png" class="articleimage">
            <figcaption>A low amount of fuzz results in a polished metallic look.</figcaption>
        </figure>
        <figure>
            <img src="static/raytracer/reflective-2-highfuzz.png" class="articleimage">
            <figcaption>A high amount of fuzz looks like a dull metallic surface.</figcaption>
        </figure>
        <figure>
            <img src="static/raytracer/reflective-2-maxfuzz.png" class="articleimage">
            <figcaption>Maximum fuzz might as well just be matte.</figcaption>
        </figure>
    </div>

    <h1>Putting It All Together</h1>
    <p>Lastly, I'll show you one final image, rendered with high resolution, to demonstrate the capabilities of the renderer. Here, I've placed spheres of random color and material in random positions. Try to look for what each metallic sphere is 
        reflecting (it may be out of the shot!) and note the depth of field blurring objects that are too close to the camera. I thought it was interesting to note that having many objects in the scene makes it look much more realistic to my eyes.
         Maybe it's the way the reflectives interact, maybe it's the shadows, or maybe there's just something less natural to our brains about those images with a single sphere alone in infinity. Regardless, here's the render:
    </p>
    <img class="articleimage" src="static/raytracer/full-scene.png" style="width: 45vw;">
    <br>
</div>
</body>
</html>
